
## Cognitive Abilities and Educational Outcomes Overview

According to the investment theory (Cattell 1967, 1971), fluid intelligence is one of the major causes of achievement differences, since it represents the individual’s capacity to solve novel problems, to make inferences, to identify relations, and to transform information.

Through investment in learning experiences, such a capacity is transformed into crystallized intelligence, which is defined as the depth and breadth of knowledge and skills that are valued by one’s culture.

. As has been observed in the educational effectiveness and attainment research, school organizational characteristics and academic processes, such as curriculum, resources, and teacher competence, explain a rather substantial part of the outcome differences.

## Cognitive Abilities History

The field of research on cognitive abilities has evolved over time, with different models and theories proposed to explain individual differences in cognitive performance. The first intelligence scale was created by Binet in France at the beginning of the twentieth century, and factor analysis was later introduced by Spearman in 1904 to propose a two-factor theory of intelligence, consisting of a g-factor of general intelligence and an s-factor of specific cognitive abilities.

Throughout the twentieth century, there were debates among researchers about the existence of a g-factor and whether all factors should be considered equal or if hierarchical models with lower order factors subsumed under higher order factors should be used. In 1966, Horn and Cattell presented a hierarchical model with a set of narrow and broad factors, among which two factors, fluid intelligence (Gf) and crystallized intelligence (Gc), are now regarded as the core concepts in the field of intelligence.

Gf represents the ability to solve novel, complex problems using inductive and deductive reasoning, while Gc represents individual differences in language, information, and concepts of a culture. The Cattell-Horn-Carroll (CHC) model is a consensus model based on three strata, with Gf and Gc identified in Stratum II and the g-factor in Stratum III. Recent research suggests that Gf is plastic and possible to improve.

Jan-Eric Gustafsson supported the hypothesis of a strong relationship between Gf and the higher order g-factor. Gf can be conceived as a domain-general ability, and separate content factors can be identified along with a Gf-factor. However, using only one type of content to measure Gf can lead to bias towards that task. A more valid measure of Gf in young children has been proposed through combining visuospatial tests with working memory and memory span tests.

## Educational Effectiveness Research (EER) Overview

EER is a multifaceted discipline that involves examining a range of factors such as instructional methods, school structure, curriculum, and learning settings. To determine the impact of school-related factors, it's important to eliminate the influence of students' family and social backgrounds. As a result, the methodological challenges of analyzing complex data across various levels of the education system are crucial in EER.

Several models have been proposed in the past, but none have fully addressed the variations in student educational outcomes. The most recent model, the Creemers and Kyriakides (2007) Dynamic Model of Educational Effectiveness, recognizes that teaching and learning practices are adaptable and ever-changing, responding to societal demands. This model enables the examination of different contributors to educational effectiveness, and exploring classroom factors to better comprehend their interplay and impact on learning outcomes is an important undertaking.

## Educational measurement Overview

Educational measurement has a rich history and has evolved over time, with test theory being at the forefront of its development. Let us discuss a bit the history and development of educational measurement, particularly the evolution of test theory and its applications.

Classical test theory (CTT) was the earliest form of test theory, but it had limitations that led to the introduction of new multivariate approaches to the measurement problem. The weaknesses of CTT were mainly due to the changes in item parameters that occurred as the group of test takers changed.

To solve this problem, the one-parameter Rasch model was developed statistically. The Rasch model enabled item difficulty to be separated from respondents' ability and vice versa, allowing researchers to compose well-balanced tests from test items. However, the Rasch model was not without its problems. It was computationally challenging to estimate the model, particularly when there were many items, and it was difficult to determine good model fit.

To address these issues, more item parameters were added to the Rasch model, such as the two-parameter logistic model and the three-parameter logistic model. Other models were also developed to allow for different types of scoring, such as partial credit-models and graded response models.

The true score model, proposed by Spearman, was another significant development in educational measurement. The model states that any manifest score is due to at least two sources of variance: true variance due to the intended construct and measurement errors.

The assumptions of unidimensionality and local independence are essential prerequisites before comparisons of ability levels are made on any test. Item response theory remains a valuable tool for developing instruments, constructing scales, linking scales, and adaptive testing.